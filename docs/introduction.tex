\section{Introduzione}

Con la sempre maggiore diffusione di dispositivi digitali, come gli smartphones, in grado di scattare immagini digitali, identificare la sorgente di tali immagini è diventata sempre più una necessità. In particolare, in ambito forense essere in grado di determinare il sensore con il quale delle immagini digitali sono state scattate, e quindi usare la loro origine come prova, è fondamentale in un'aula di tribunale. Tali metodi di identificazione della sorgente permetterebbero di stabilire se un'immagine digitale è stata elaborata o meno tramite l'uso di specifici software. I problemi da affrontare sono dunque la provenienza e l'autenticità di un'immagine digitale.

L'idea generale dietro tali approcci di identificazione è che ciascun dispositivo (fotocamera, smartphone, ecc) utilizza un proprio sensore che lascia un'impronta univoca sulle immagine che acquisisce. Questa fingerprint è dovuta a delle imperfezioni che sono intrinseche del processo di acquisizione stesso delle immagini digitali e perciò caratterizzano univocamente un sensore digitale. In genere, tale fingerprint è calcolata estraendo la \emph{Photo Response Non-Uniformity} (PRNU) da un'immagine attraverso delle operazioni di filtraggio digitale che estraggono il rumore intrinseco nell'immagine.

Il caso più banale per determinare la sorgente di un'immagine digitale è quella di confrontare la sua PRNU con le fingerprint relative ad un'insieme di dispositivi di cui siamo in possesso; a questo punto si tratta semplicemente di utilizzare una misura per stabilire la fingerprint più vicina alla PRNU dell'immagine ignota ed assegnarle il relativo sensore come sorgente di provenienza.

Tuttavia, lavorare in uno scenario chiuso, ovvero con un'insieme di immagini di cui è già stata stabilita l'origine, è una situazione poco realistica. Il caso più frequente è quello di avere una serie di immagini provenienti da dispositivi non identificati che non sono in nostro possesso. In ambito forense, tale scenario potrebbe presentarsi quando siamo in possesso di un insieme di fotografie e il nostro compito è determinare se tali immagini digitali provengono o meno dallo stesso dispositivo.

Avere dei metodi efficaci ed efficienti in grado di determinare automaticamente se un'insieme di immagini digitali hanno o meno la stessa sorgente ha importanti ricadute applicative. Un caso importante è il loro utilizzo con i social networks, che contengono sempre più immagini. Il caso dei social networks come Facebook è un classico esempio di scenario aperto, similmente a come descritto in precedenza, dove sono mostrate una serie di immagini di cui non è noto a priori né il dispositivo con cui tali immagini sono state acquisite, né il numero di dispositivi utilizzati. Lavorare con i social networks è un banco di prova importante per tali metodi di identificazione automatica delle camere. Infatti la maggioranza dei social network, per risparmiare spazio di archiviazione, utilizzano algoritmi di compressione per ridurre la dimensione delle immagini che un'utente carica. Tale compressione ha, in genere, effetti negativi sulla PRNU di un'immagine digitale, ovvero viene persa parte di informazione, inteso come rumore, che lo distinguerebbe dalle altre immagini.

Un esempio di metodo per l'identificazione di dispositivi è quello presentato da \cite{Amerini2014831}. Il metodo si basa sull'estrazione delle PRNU da ciascuna immagine di cui si vuole determinare la provenienza. Per ciascuna coppia di PRNU, viene stimata una similarità fra i rumori utilizzando la cross-correlazione normalizzata, creando così un grafo completamente connesso, che può essere rappresentato da una matrice quadrata. A questo punto un algoritmo di clusterizzazione viene eseguito sul grafo per separare gruppi di rumori simili nel dataset. L'algoritmo di clustering che gli autori hanno scelto è Normalized Cuts, che si adatta perfettamente ad un scenario aperto, non essendo necessario stabilire a priori il numero di clusters da calcolare. La condizione di stop dell'algoritmo di clustering, che è ricorsivo, è l'\emph{Aggregation Coefficient}, implementato dagli autori per stabilire la similitudine fra un'insieme di immagini e decidere se questo deve essere ulteriormente diviso. A partire dalle PRNU di ciascun cluster ottenuto, viene calcolata la fingerprint che identificherà tale insieme di immagini.

A partire da tale metodo, il nostro lavoro presenta alcune variazioni:
\begin{enumerate}
\item Al posto della cross-correlazione normalizzata, abbiamo usato la Peak-to-Correlation Energy (PCE), anch'essa una misura di similarità fra due segnali discreti che è particolarmente adatta a confrontare \emph{fingerprints}, ovvero le PRNU, di due immagini digitali.
\item Per la condizione di stop di Normalized Cuts, è stata usato il valore di ncut, ovvero il costo del taglio del grafo per quella specifica bipartizione. La scelta sul non usare l'Aggregation Coefficient verrà data in una sezione successiva di questo articolo.
\end{enumerate}

Le immagini utilizzate per valutare le performance di questo metodo sono sia immagini prese direttamente dopo l'acquisizione sia dopo essere stata caricate e poi riscaricate da Facebook, subendo quindi una compressione.

L'articolo è organizzato come segue: la Sezione 2 descrive la fase di estrazione delle PRNU; la Sezione 3 presenta in maggiore dettaglio l'algoritmo Normalized Cuts usato per la clusterizzazione delle PRNU e l'utilizzo della PCE per il calcolo del grafo pesato; la Sezione 4 fornisce dettagli su come le fingerprints sono calcolate a partire da ciascun cluster ottenuto; la Sezione 5 spiega come funziona il processo di validazione delle fingerprints ottenute; la Sezione 6 commenta i risultati e infine la Sezione 7 conclude l'articolo.